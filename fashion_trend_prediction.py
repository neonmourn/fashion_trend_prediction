# -*- coding: utf-8 -*-
"""Fashion_Trend_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HeMQEgl37s9W_A14ffCiuFUOkPK9f1xH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as ply
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler

"""Importing the Kaggle dataset as a dataframe

"""

df=pd.read_csv('summer-products.csv')

df.head()

df.describe()

df.info()

"""Data Cleaning"""

df=df.drop(['merchant_profile_picture'],axis=1)

df=df.drop(['urgency_text'],axis=1)

df=df.drop(['merchant_name'],axis=1)

df=df.drop(['merchant_info_subtitle'],axis=1)

df['has_urgency_banner'] = df['has_urgency_banner'].fillna(0)

df['rating_five_count'] = df['rating_five_count'].fillna(0)

df['rating_four_count'] = df['rating_four_count'].fillna(0)
df['rating_three_count'] = df['rating_three_count'].fillna(0)
df['rating_two_count'] = df['rating_two_count'].fillna(0)
df['rating_one_count'] = df['rating_one_count'].fillna(0)

df['product_variation_size_id'] = df['product_variation_size_id'].fillna(0)

df.dropna(subset=['origin_country'], inplace=True)

mode_value = df['product_color'].mode()[0]
print(mode_value)
df['product_color'].fillna(mode_value, inplace=True)

columns_to_drop = [
    'title',
    'currency_buyer',
    'badges_count',
    'badge_local_product',
    'badge_product_quality',
    'badge_fast_shipping',
    'shipping_option_name',
    'shipping_option_price',
    'shipping_is_express',
    'has_urgency_banner',

    'merchant_title',


    'merchant_rating_count',
    'merchant_rating',
    'merchant_id',
    'merchant_has_profile_picture',

    'product_color'
]

# Drop the specified columns
df.drop(columns=columns_to_drop, inplace=True)

df['uses_ad_boosts'].unique()

df=df.drop(['crawl_month'],axis=1)

df=df.drop(['theme'],axis=1)

df=df.drop(['retail_price'],axis=1)

object_columns = df.select_dtypes(include=['object']).columns.tolist()

print("Columns with data type 'object':")
print(object_columns)

df=df.drop(['product_url'],axis=1)

"""One Hot Encoding"""

df_encoded = pd.get_dummies(df, columns=['title_orig', 'product_variation_size_id', 'origin_country','tags'], dtype=int)

df_encoded.shape

df_encoded.head()

"""Normalization using MinMax Scaling"""

scaler = MinMaxScaler()
columns_to_scale = ['price', 'units_sold', 'uses_ad_boosts', 'rating', 'rating_count','rating_five_count','rating_four_count','rating_three_count','rating_two_count','rating_one_count','countries_shipped_to','inventory_total','product_variation_inventory']
df_encoded[columns_to_scale] = scaler.fit_transform(df_encoded[columns_to_scale])

"""Feature Engineering: Adding LAG Features"""

def create_lag_features(df_encoded, column_name, lags):
    for lag in lags:
        df_encoded[f'{column_name}_lag_{lag}'] = df_encoded[column_name].shift(lag)
    return df_encoded

lags = [1, 2, 3]

df_encoded = create_lag_features(df_encoded, 'units_sold', lags)

print("\nDataFrame with Lag Features:")
print(df_encoded)

"""To find the coorelation matrix of the dataset"""

df_test=df_encoded.drop(['product_id','product_picture'],axis=1)
correlation_matrix =df_test.corr()

"""Splitting data into training and test sets and applying Logistic Regression"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score


# Calculate the threshold BEFORE dropping the 'sales_count' column
threshold = df_test['units_sold'].median()

# Encode sales_count as binary
df_test['units_sold_binary'] = (df_test['units_sold'] > threshold).astype(int)

# Encode lagged sales counts as binary
df_test['units_sold_lag_1_binary'] = (df_test['units_sold_lag_1'] > threshold).astype(int)
df_test['units_sold_lag_2_binary'] = (df_test['units_sold_lag_2'] > threshold).astype(int)
df_test['units_sold_lag_3_binary'] = (df_test['units_sold_lag_3'] > threshold).astype(int)

# Drop the original continuous sales_count and lagged sales counts
df_test = df_test.drop(columns=['units_sold', 'units_sold_lag_1', 'units_sold_lag_2', 'units_sold_lag_2'])


# Verify the distribution of the target variable
print("Distribution of the target variable:")
print(df_test['units_sold_binary'].value_counts())

# Independent variables
X = df_test.drop(columns=['units_sold_binary'])

X = X.apply(pd.to_numeric, errors='coerce').fillna(0)

# Dependent variable (binary encoded)
y = df_test['units_sold_binary']

# Splitting data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Creating and training the logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Making predictions
y_pred = model.predict(X_test)

y_pred_prob = model.predict_proba(X_test)[:, 1]  # probabilities needed for ROC AUC

# Calculating accuracy metrics
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_prob)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")
print(f"ROC AUC Score: {roc_auc}")
print("Confusion Matrix:")
print(conf_matrix)

"""We have analyzed the accuracy of our model above

Function to use the model for user image
"""

def predict_and_compare(model, feature_row, actual_target):
    prediction = model.predict([feature_row])
    prediction_prob = model.predict_proba([feature_row])[0][1]
    is_correct = prediction[0] == actual_target
    print(f"Features: {feature_row}")
    print(f"Predicted: {prediction[0]}, Actual: {actual_target}, Probability: {prediction_prob:.4f}")
    print(f"Correct Prediction: {is_correct}")
    return is_correct

# Test the function with a sample row from the test set
sample_index = 7 # Change this to test different rows
sample_features = X_test.iloc[sample_index ]
sample_actual_target = y_test.iloc[sample_index ]

predict_and_compare(model, sample_features, sample_actual_target)

"""Importing the VGG16 model from tensorflow.keras to extract features from the image uploaded"""

from tensorflow.keras.models import Model

from tensorflow.keras.preprocessing import image

import os
from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import load_img, img_to_array

from tensorflow.keras.models import Model

from tensorflow.keras.preprocessing.image import load_img, img_to_array

pip install tensorflow.keras.preprocessing.image

model=VGG16()
print(model.summary())

model=Model(inputs=model.inputs,outputs=model.layers[-2].output)

datamod=VGG16()
print(datamod.summary())

datamod=Model(inputs=model.inputs,outputs=model.layers[-2].output)

"""Using VGG16 Model to extract features of the products in our dataset and finding the most similar product to the user image for trend prediction"""

from keras_preprocessing.image import load_img

from tensorflow.keras.utils import load_img

datafeatures={}
dataimage_files = ['test.png','testagain.png']

datadirectory='/dataimgs'

for image in dataimage_files:


  dataimage_path = os.path.join(datadirectory, image)

  dataimg=load_img(dataimage_path,target_size=(224,224))

  dataimg=img_to_array(dataimg)
  dataimg =dataimg.reshape((1,dataimg.shape[0],dataimg.shape[1],dataimg.shape[2]))
  dataimg=preprocess_input(dataimg)
  datafeature=model.predict(dataimg,verbose=0)
  datafeatures[dataimage_path]=datafeature

datafeatures['/dataimgs/testagain.png']

datafeatures['/dataimgs/test.png']

fullfeatures=[]

for imgg_path in datafeatures:
    fullfeatures.extend(datafeatures[imgg_path])
print(fullfeatures)
#print(datafeatures[imgg_path])

print(fullfeatures)

df_encoded['features'] = np.nan

"""Adding the features from the VGG16 Model to a newly created 'Features' column in our dataframe"""

df_encoded.loc[:2,df.columns.get_loc('features')]=fullfeatures

df.drop('features',axis=1,inplace=True)